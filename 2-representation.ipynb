{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Cleaned Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cleaned datasets\n",
    "train_df = pd.read_csv('E:\\\\Vocational\\\\Lighthouse Labs\\\\Flex Course\\\\Projects\\\\P05_Large Language Models\\\\llm_project\\\\data\\\\cleaned_train.csv.gz', compression='gzip')\n",
    "test_df = pd.read_csv('E:\\\\Vocational\\\\Lighthouse Labs\\\\Flex Course\\\\Projects\\\\P05_Large Language Models\\\\llm_project\\\\data\\\\cleaned_test.csv.gz', compression='gzip')\n",
    "\n",
    "# Extract labels\n",
    "y_train = train_df['label']\n",
    "y_test = test_df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate TF-IDF and BoW Representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize vectorizers\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "bow_vectorizer = CountVectorizer(max_features=5000)\n",
    "\n",
    "# Fit and transform the train datasets, and transform the test datasets\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(train_df['clean_text'])\n",
    "X_test_tfidf = tfidf_vectorizer.transform(test_df['clean_text'])\n",
    "\n",
    "X_train_bow = bow_vectorizer.fit_transform(train_df['clean_text'])\n",
    "X_test_bow = bow_vectorizer.transform(test_df['clean_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a Function to Train and Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print(f'F1 Score: {f1}')\n",
    "    print('Confusion Matrix:')\n",
    "    print(cm)\n",
    "    print('Classification Report:')\n",
    "    print(report)\n",
    "    \n",
    "    return accuracy, precision, recall, f1, cm, report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and Evaluate Models for TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Representation\n",
      "Logistic Regression\n",
      "Accuracy: 0.8771420507237612\n",
      "Precision: 0.8745513996331445\n",
      "Recall: 0.8815112540192926\n",
      "F1 Score: 0.8780175347291725\n",
      "Confusion Matrix:\n",
      "[[10788  1573]\n",
      " [ 1474 10966]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.87      0.88     12361\n",
      "           1       0.87      0.88      0.88     12440\n",
      "\n",
      "    accuracy                           0.88     24801\n",
      "   macro avg       0.88      0.88      0.88     24801\n",
      "weighted avg       0.88      0.88      0.88     24801\n",
      "\n",
      "Random Forest\n",
      "Accuracy: 0.8425869924599815\n",
      "Precision: 0.8534282875124213\n",
      "Recall: 0.8284565916398714\n",
      "F1 Score: 0.8407570566160875\n",
      "Confusion Matrix:\n",
      "[[10591  1770]\n",
      " [ 2134 10306]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.84     12361\n",
      "           1       0.85      0.83      0.84     12440\n",
      "\n",
      "    accuracy                           0.84     24801\n",
      "   macro avg       0.84      0.84      0.84     24801\n",
      "weighted avg       0.84      0.84      0.84     24801\n",
      "\n",
      "Gradient Boosting\n",
      "Accuracy: 0.8064997379137938\n",
      "Precision: 0.7760277436601402\n",
      "Recall: 0.8634244372990354\n",
      "F1 Score: 0.8173965983029565\n",
      "Confusion Matrix:\n",
      "[[ 9261  3100]\n",
      " [ 1699 10741]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.75      0.79     12361\n",
      "           1       0.78      0.86      0.82     12440\n",
      "\n",
      "    accuracy                           0.81     24801\n",
      "   macro avg       0.81      0.81      0.81     24801\n",
      "weighted avg       0.81      0.81      0.81     24801\n",
      "\n",
      "SVM\n",
      "Accuracy: 0.8695213902665215\n",
      "Precision: 0.8721494420184377\n",
      "Recall: 0.8669614147909968\n",
      "F1 Score: 0.8695476900749819\n",
      "Confusion Matrix:\n",
      "[[10780  1581]\n",
      " [ 1655 10785]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87     12361\n",
      "           1       0.87      0.87      0.87     12440\n",
      "\n",
      "    accuracy                           0.87     24801\n",
      "   macro avg       0.87      0.87      0.87     24801\n",
      "weighted avg       0.87      0.87      0.87     24801\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8695213902665215,\n",
       " 0.8721494420184377,\n",
       " 0.8669614147909968,\n",
       " 0.8695476900749819,\n",
       " array([[10780,  1581],\n",
       "        [ 1655, 10785]], dtype=int64),\n",
       " '              precision    recall  f1-score   support\\n\\n           0       0.87      0.87      0.87     12361\\n           1       0.87      0.87      0.87     12440\\n\\n    accuracy                           0.87     24801\\n   macro avg       0.87      0.87      0.87     24801\\nweighted avg       0.87      0.87      0.87     24801\\n')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"TF-IDF Representation\")\n",
    "\n",
    "# Logistic Regression\n",
    "print(\"Logistic Regression\")\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "train_and_evaluate_model(lr_model, X_train_tfidf, y_train, X_test_tfidf, y_test)\n",
    "\n",
    "# Random Forest\n",
    "print(\"Random Forest\")\n",
    "rf_model = RandomForestClassifier(n_estimators=100)\n",
    "train_and_evaluate_model(rf_model, X_train_tfidf, y_train, X_test_tfidf, y_test)\n",
    "\n",
    "# Gradient Boosting\n",
    "print(\"Gradient Boosting\")\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100)\n",
    "train_and_evaluate_model(gb_model, X_train_tfidf, y_train, X_test_tfidf, y_test)\n",
    "\n",
    "# SVM\n",
    "print(\"SVM\")\n",
    "svm_model = SVC(kernel='linear', probability=True)\n",
    "train_and_evaluate_model(svm_model, X_train_tfidf, y_train, X_test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion:\n",
    "\n",
    "Logistic Regression and SVM are the top performers with very similar results. If the goal is to minimize false negatives and ensure most positive cases are correctly identified, Logistic Regression would be preferred due to its slightly higher recall. However, if the goal is to have a balanced performance with a slight edge in precision, SVM would be a strong choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and Evaluate Models for BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW Representation\n",
      "Logistic Regression\n",
      "Accuracy: 0.8439982258779888\n",
      "Precision: 0.8510690587367904\n",
      "Recall: 0.8351286173633441\n",
      "F1 Score: 0.8430234917028442\n",
      "Confusion Matrix:\n",
      "[[10543  1818]\n",
      " [ 2051 10389]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.85      0.84     12361\n",
      "           1       0.85      0.84      0.84     12440\n",
      "\n",
      "    accuracy                           0.84     24801\n",
      "   macro avg       0.84      0.84      0.84     24801\n",
      "weighted avg       0.84      0.84      0.84     24801\n",
      "\n",
      "Random Forest\n",
      "Accuracy: 0.8395629208499658\n",
      "Precision: 0.8466202376075379\n",
      "Recall: 0.8306270096463022\n",
      "F1 Score: 0.8385473726922297\n",
      "Confusion Matrix:\n",
      "[[10489  1872]\n",
      " [ 2107 10333]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.85      0.84     12361\n",
      "           1       0.85      0.83      0.84     12440\n",
      "\n",
      "    accuracy                           0.84     24801\n",
      "   macro avg       0.84      0.84      0.84     24801\n",
      "weighted avg       0.84      0.84      0.84     24801\n",
      "\n",
      "Gradient Boosting\n",
      "Accuracy: 0.807306157009798\n",
      "Precision: 0.7772710821570756\n",
      "Recall: 0.8631832797427653\n",
      "F1 Score: 0.8179775280898877\n",
      "Confusion Matrix:\n",
      "[[ 9284  3077]\n",
      " [ 1702 10738]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.75      0.80     12361\n",
      "           1       0.78      0.86      0.82     12440\n",
      "\n",
      "    accuracy                           0.81     24801\n",
      "   macro avg       0.81      0.81      0.81     24801\n",
      "weighted avg       0.81      0.81      0.81     24801\n",
      "\n",
      "SVM\n",
      "Accuracy: 0.8283536954155074\n",
      "Precision: 0.837721832439125\n",
      "Recall: 0.8158360128617363\n",
      "F1 Score: 0.8266340867440439\n",
      "Confusion Matrix:\n",
      "[[10395  1966]\n",
      " [ 2291 10149]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83     12361\n",
      "           1       0.84      0.82      0.83     12440\n",
      "\n",
      "    accuracy                           0.83     24801\n",
      "   macro avg       0.83      0.83      0.83     24801\n",
      "weighted avg       0.83      0.83      0.83     24801\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8283536954155074,\n",
       " 0.837721832439125,\n",
       " 0.8158360128617363,\n",
       " 0.8266340867440439,\n",
       " array([[10395,  1966],\n",
       "        [ 2291, 10149]], dtype=int64),\n",
       " '              precision    recall  f1-score   support\\n\\n           0       0.82      0.84      0.83     12361\\n           1       0.84      0.82      0.83     12440\\n\\n    accuracy                           0.83     24801\\n   macro avg       0.83      0.83      0.83     24801\\nweighted avg       0.83      0.83      0.83     24801\\n')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"BoW Representation\")\n",
    "\n",
    "# Logistic Regression\n",
    "print(\"Logistic Regression\")\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "train_and_evaluate_model(lr_model, X_train_bow, y_train, X_test_bow, y_test)\n",
    "\n",
    "# Random Forest\n",
    "print(\"Random Forest\")\n",
    "rf_model = RandomForestClassifier(n_estimators=100)\n",
    "train_and_evaluate_model(rf_model, X_train_bow, y_train, X_test_bow, y_test)\n",
    "\n",
    "# Gradient Boosting\n",
    "print(\"Gradient Boosting\")\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100)\n",
    "train_and_evaluate_model(gb_model, X_train_bow, y_train, X_test_bow, y_test)\n",
    "\n",
    "# SVM\n",
    "print(\"SVM\")\n",
    "svm_model = SVC(kernel='linear', probability=True)\n",
    "train_and_evaluate_model(svm_model, X_train_bow, y_train, X_test_bow, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall Comparison:\n",
    "- **Best Performance**: Logistic Regression with TF-IDF achieved the highest scores in all evaluation metrics.\n",
    "- **Consistency**: Gradient Boosting showed consistent results with both TF-IDF and BoW, but with slightly better performance using TF-IDF.\n",
    "- **Model Preference**: Based on the results, TF-IDF representation generally outperformed BoW representation across all models. Logistic Regression and SVM models particularly benefitted from the TF-IDF representation.\n",
    "\n",
    "### Final Recommendation\n",
    "\n",
    "For deployment and further optimization, **Logistic Regression with TF-IDF representation** is recommended due to its superior performance across all metrics. SVM with TF-IDF is also a strong contender and can be considered if a slight trade-off in precision is acceptable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
